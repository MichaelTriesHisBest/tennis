{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on pp. 188-189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal:    [[1]]\n",
      "Layer 1: [[0.86]]\n",
      "Weights: [[0.100000],\n",
      "          [0.200000],\n",
      "          [-0.100000]]\n",
      "Layer 0: [[8.5  0.65 1.2 ]]\n",
      "\n",
      "Goal:    [[1]]\n",
      "Layer 1: [[0.9637575]]\n",
      "Weights: [[0.111900],\n",
      "          [0.200910],\n",
      "          [-0.098320]]\n",
      "Layer 0: [[8.5  0.65 1.2 ]]\n",
      "\n",
      "Goal:    [[1]]\n",
      "Layer 1: [[0.99061772]]\n",
      "Weights: [[0.114981],\n",
      "          [0.201146],\n",
      "          [-0.097885]]\n",
      "Layer 0: [[8.5  0.65 1.2 ]]\n",
      "\n",
      "Goal:    [[1]]\n",
      "Layer 1: [[0.99757116]]\n",
      "Weights: [[0.115778],\n",
      "          [0.201207],\n",
      "          [-0.097773]]\n",
      "Layer 0: [[8.5  0.65 1.2 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from NNet import NNet\n",
    "\n",
    "weights = [[[0.1],\n",
    "            [0.2],\n",
    "            [-0.1]]]\n",
    "alphas = [0.01]\n",
    "nn = NNet(weights)\n",
    "nn.setAlphas(alphas)\n",
    "\n",
    "input = numpy.array([[8.5, 0.65, 1.2]])\n",
    "goal = numpy.array([[1]])\n",
    "for i in range(4):\n",
    "    output = nn.fire(input)\n",
    "    print('Goal:    ' + str(goal))\n",
    "    print(nn)\n",
    "    nn.learn(input, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on pp. 226-227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[[2.65612311]]\n",
      "Error:[[0.96287018]]\n",
      "Error:[[0.55091659]]\n",
      "Error:[[0.36445837]]\n",
      "Error:[[0.25167687]]\n",
      "Error:[[0.17797575]]\n",
      "Error:[[0.12864461]]\n",
      "Error:[[0.09511037]]\n",
      "Error:[[0.07194564]]\n",
      "Error:[[0.05564915]]\n",
      "Error:[[0.04394764]]\n",
      "Error:[[0.03535797]]\n",
      "Error:[[0.028907]]\n",
      "Error:[[0.02395166]]\n",
      "Error:[[0.02006311]]\n",
      "Error:[[0.01695209]]\n",
      "Error:[[0.01442082]]\n",
      "Error:[[0.01233174]]\n",
      "Error:[[0.01058739]]\n",
      "Error:[[0.00911723]]\n",
      "Error:[[0.00786904]]\n",
      "Error:[[0.00680327]]\n",
      "Error:[[0.0058893]]\n",
      "Error:[[0.00510293]]\n",
      "Error:[[0.00442464]]\n",
      "Error:[[0.00383851]]\n",
      "Error:[[0.00333131]]\n",
      "Error:[[0.00289194]]\n",
      "Error:[[0.00251105]]\n",
      "Error:[[0.00218067]]\n",
      "Error:[[0.00189397]]\n",
      "Error:[[0.00164511]]\n",
      "Error:[[0.00142904]]\n",
      "Error:[[0.0012414]]\n",
      "Error:[[0.00107844]]\n",
      "Error:[[0.00093689]]\n",
      "Error:[[0.00081394]]\n",
      "Error:[[0.00070713]]\n",
      "Error:[[0.00061434]]\n",
      "Error:[[0.00053374]]\n",
      "Layer 1: [[-0.00262562]]\n",
      "Weights: [[0.013892],\n",
      "          [1.013815],\n",
      "          [-0.015993]]\n",
      "Layer 0: [[1 0 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    import numpy as np\n",
    "    from NNet import NNet\n",
    "\n",
    "    nn = NNet([[[0.5],\n",
    "                [0.48],\n",
    "                [-0.7]]])\n",
    "    nn.setAlphas([0.1])\n",
    "\n",
    "    streetlights = np.array([[1, 0, 1],\n",
    "                             [0, 1, 1],\n",
    "                             [0, 0, 1],\n",
    "                             [1, 1, 1],\n",
    "                             [0, 1, 1],\n",
    "                             [1, 0, 1]])\n",
    "\n",
    "    walk_vs_stop = np.array([[0, 1, 0, 1, 1, 0]]).T\n",
    "\n",
    "    datain = streetlights[0]  # [1,0,1]\n",
    "    goal_prediction = walk_vs_stop[0]  # equals 0... i.e. \"stop\"\n",
    "\n",
    "    verbose = False\n",
    "    def vprint(s):\n",
    "        if verbose:\n",
    "            print(s)\n",
    "\n",
    "    for iteration in range(40):\n",
    "        vprint('~~~~~~~~~~~ Iteration %d ~~~~~~~~~~~' % iteration)\n",
    "        error_for_all_lights = 0\n",
    "        for row_index in range(len(walk_vs_stop)):\n",
    "            datain = streetlights[row_index:row_index+1]\n",
    "            goal_prediction = walk_vs_stop[row_index:row_index+1]\n",
    "            prediction = nn.fire(datain)\n",
    "            # print('Prediction:' + str(prediction))\n",
    "            vprint(nn)\n",
    "\n",
    "            error = (goal_prediction - prediction) ** 2\n",
    "            error_for_all_lights += error\n",
    "\n",
    "            nn.learn(datain, goal_prediction)\n",
    "\n",
    "        print(\"Error:\" + str(error_for_all_lights))\n",
    "        vprint('')\n",
    "    vprint('~~~~~~~~~~~~~~~ End ~~~~~~~~~~~~~~~~')\n",
    "    print(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...but what happens if the problem is a little harder?\n",
    "\n",
    "This is the same neural net, with a shorter set to learn, but the error does not drop to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[[3.490269]]\n",
      "Error:[[2.73135902]]\n",
      "Error:[[2.40459207]]\n",
      "Error:[[2.21518015]]\n",
      "Error:[[2.08027017]]\n",
      "Error:[[1.97321711]]\n",
      "Error:[[1.88378038]]\n",
      "Error:[[1.80717553]]\n",
      "Error:[[1.74072358]]\n",
      "Error:[[1.6826847]]\n",
      "Error:[[1.63179743]]\n",
      "Error:[[1.58707581]]\n",
      "Error:[[1.54771178]]\n",
      "Error:[[1.51302396]]\n",
      "Error:[[1.4824283]]\n",
      "Error:[[1.45541947]]\n",
      "Error:[[1.43155795]]\n",
      "Error:[[1.41046033]]\n",
      "Error:[[1.3917915]]\n",
      "Error:[[1.37525829]]\n",
      "Error:[[1.36060401]]\n",
      "Error:[[1.34760377]]\n",
      "Error:[[1.33606048]]\n",
      "Error:[[1.32580133]]\n",
      "Error:[[1.31667473]]\n",
      "Error:[[1.30854764]]\n",
      "Error:[[1.30130328]]\n",
      "Error:[[1.29483906]]\n",
      "Error:[[1.28906487]]\n",
      "Error:[[1.28390146]]\n",
      "Error:[[1.27927913]]\n",
      "Error:[[1.27513655]]\n",
      "Error:[[1.2714197]]\n",
      "Error:[[1.26808101]]\n",
      "Error:[[1.26507853]]\n",
      "Error:[[1.26237524]]\n",
      "Error:[[1.25993847]]\n",
      "Error:[[1.25773938]]\n",
      "Error:[[1.25575244]]\n",
      "Error:[[1.25395507]]\n",
      "Layer 1: [[0.59955275]]\n",
      "Weights: [[0.044807],\n",
      "          [-0.013149],\n",
      "          [0.388029]]\n",
      "Layer 0: [[1 1 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from NNet import NNet\n",
    "\n",
    "nn = NNet([[[0.5],\n",
    "            [0.48],\n",
    "            [-0.7]]])\n",
    "nn.setAlphas([0.1])\n",
    "\n",
    "streetlights = np.array([[[1, 0, 1]],\n",
    "                         [[0, 1, 1]],\n",
    "                         [[0, 0, 1]],\n",
    "                         [[1, 1, 1]]])\n",
    "\n",
    "walk_vs_stop = np.array([[[1, 1, 0, 0]]]).T\n",
    "\n",
    "input = streetlights[0]  # [1,0,1]\n",
    "goal_prediction = walk_vs_stop[0]  # equals 0... i.e. \"stop\"\n",
    "\n",
    "verbose = False\n",
    "def vprint(s):\n",
    "    if verbose:\n",
    "        print(s)\n",
    "\n",
    "for iteration in range(40):\n",
    "    vprint('~~~~~~~~~~~ Iteration %d ~~~~~~~~~~~' % iteration)\n",
    "    error_for_all_lights = 0\n",
    "    for row_index in range(len(walk_vs_stop)):\n",
    "        input = streetlights[row_index]\n",
    "        goal_prediction = walk_vs_stop[row_index]\n",
    "        prediction = nn.fire(input)\n",
    "        # print('Prediction:' + str(prediction))\n",
    "        vprint(nn)\n",
    "\n",
    "        error = (goal_prediction - prediction) ** 2\n",
    "        error_for_all_lights += error\n",
    "\n",
    "        nn.learn(input, goal_prediction)\n",
    "\n",
    "    print(\"Error:\" + str(error_for_all_lights))\n",
    "    vprint('')\n",
    "vprint('~~~~~~~~~~~~~~~ End ~~~~~~~~~~~~~~~~')\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on pp. 260-265 (with a verbose option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.6342311598444467\n",
      "Error:0.35838407676317513\n",
      "Error:0.0830183113303298\n",
      "Error:0.006467054957103705\n",
      "Error:0.0003292669000750734\n",
      "Error:1.5055622665134859e-05\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "def vprint(s):\n",
    "    if verbose:\n",
    "        print(s)\n",
    "\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x  # returns x if x > 0\n",
    "    # return 0 otherwise\n",
    "\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0  # returns 1 for input > 0\n",
    "    # return 0 otherwise\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "layer_0 = [nan] * 3\n",
    "layer_1 = [nan] * 4\n",
    "layer_2 = nan\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "def weights2str(weights):\n",
    "    s = ''\n",
    "    rs = 'Weights: [['\n",
    "    for row in weights:\n",
    "        firstCol = True\n",
    "        for col in row:\n",
    "            if not firstCol:\n",
    "                rs += ', '\n",
    "            firstCol = False\n",
    "            rs += '%f' % col\n",
    "        s += rs + ']'\n",
    "        rs = ',\\n          ['\n",
    "    s += ']'\n",
    "    return s\n",
    "\n",
    "def vprintnn():\n",
    "    if not verbose:\n",
    "        return\n",
    "\n",
    "    print('Layer 2: ' + str(layer_2))\n",
    "    print(weights2str(weights_1_2))\n",
    "    print('Layer 1: ' + str(layer_1))\n",
    "    print(weights2str(weights_0_1))\n",
    "    print('Layer 0: ' + str(layer_0))\n",
    "    print('')\n",
    "\n",
    "nIterations = 60\n",
    "# verbose = True\n",
    "# nIterations = 5\n",
    "\n",
    "for iteration in range(nIterations):\n",
    "    vprint('~~~~~~~~~~~ Iteration %d ~~~~~~~~~~~' % iteration)\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        layer_0 = streetlights[i:i + 1]\n",
    "        # layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        goal = walk_vs_stop[i:i + 1]\n",
    "        vprint('Goal:   ' + str(goal))\n",
    "        vprintnn()\n",
    "\n",
    "        layer_2_error += np.sum((layer_2 - goal) ** 2)\n",
    "\n",
    "        layer_2_delta = (layer_2 - goal)\n",
    "        derivative = relu2deriv(layer_1)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * derivative\n",
    "\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if (iteration % 10 == 9):\n",
    "        print(\"Error:\" + str(layer_2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same example using NNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2: [nan]\n",
      "Weights: [[-0.591096],\n",
      "          [0.756235],\n",
      "          [-0.945225],\n",
      "          [0.340935]]\n",
      "Layer 1: [nan, nan, nan, nan]\n",
      "Weights: [[-0.165956, 0.440649, -0.999771, -0.395335],\n",
      "          [-0.706488, -0.815323, -0.627480, -0.308879],\n",
      "          [-0.206465, 0.077633, -0.161611, 0.370439]]\n",
      "Layer 0: [nan, nan, nan]\n",
      "\n",
      "Error:[[0.63423116]]\n",
      "Error:[[0.35838408]]\n",
      "Error:[[0.08301831]]\n",
      "Error:[[0.00646705]]\n",
      "Error:[[0.00032927]]\n",
      "Error:[[1.50556227e-05]]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "def vprint(s):\n",
    "    if verbose:\n",
    "        print(s)\n",
    "\n",
    "import numpy as np\n",
    "from NNet import NNet\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "nn = NNet(sizes=[3, 4, 1])\n",
    "nn.setAlphas([0.2, 0.2])\n",
    "nn.setActivations(['relu', 'linear'])\n",
    "print(nn)\n",
    "\n",
    "nIterations = 60\n",
    "# verbose = True\n",
    "# nIterations = 5\n",
    "\n",
    "for iteration in range(nIterations):\n",
    "    vprint('~~~~~~~~~~~ Iteration %d ~~~~~~~~~~~' % iteration)\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        input = streetlights[i:i+1]\n",
    "        prediction = nn.fire(input)\n",
    "        goal = walk_vs_stop[i:i+1]\n",
    "        vprint('Goal:   ' + str(goal))\n",
    "        # print('Prediction:' + str(prediction))\n",
    "        vprint(nn)\n",
    "\n",
    "        error = (goal - prediction) ** 2\n",
    "        layer_2_error += error\n",
    "\n",
    "        nn.learn(input, goal)\n",
    "\n",
    "    if (iteration % 10 == 9):\n",
    "        print(\"Error:\" + str(layer_2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "import os\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()    # this operation fails ...\n",
    "download = os.getcwd() + '/../grokking-data/mnist.npz'        # ... so I cached a copy here\n",
    "# print(download)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(download)\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example, pp. 283-284, ouput on pp. 288-289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:0 Train-Err:0.722 Train-Acc:0.537 Test-Err:0.601 Test-Acc:0.6488\n",
      " I:10 Train-Err:0.312 Train-Acc:0.901 Test-Err:0.420 Test-Acc:0.8114\n",
      " I:20 Train-Err:0.260 Train-Acc:0.937 Test-Err:0.414 Test-Acc:0.8111\n",
      " I:30 Train-Err:0.232 Train-Acc:0.946 Test-Err:0.417 Test-Acc:0.8066\n",
      " I:40 Train-Err:0.215 Train-Acc:0.956 Test-Err:0.426 Test-Acc:0.8019\n",
      " I:50 Train-Err:0.204 Train-Acc:0.966 Test-Err:0.437 Test-Acc:0.7982\n",
      " I:60 Train-Err:0.194 Train-Acc:0.967 Test-Err:0.448 Test-Acc:0.7921\n",
      " I:70 Train-Err:0.186 Train-Acc:0.975 Test-Err:0.458 Test-Acc:0.7864\n",
      " I:80 Train-Err:0.179 Train-Acc:0.979 Test-Err:0.466 Test-Acc:0.7817\n",
      " I:90 Train-Err:0.172 Train-Acc:0.981 Test-Err:0.474 Test-Acc:0.7758\n",
      " I:100 Train-Err:0.166 Train-Acc:0.984 Test-Err:0.482 Test-Acc:0.7706\n",
      " I:110 Train-Err:0.161 Train-Acc:0.984 Test-Err:0.489 Test-Acc:0.7686\n",
      " I:120 Train-Err:0.157 Train-Acc:0.986 Test-Err:0.496 Test-Acc:0.766\n",
      " I:130 Train-Err:0.153 Train-Acc:0.999 Test-Err:0.502 Test-Acc:0.7622\n",
      " I:140 Train-Err:0.149 Train-Acc:0.991 Test-Err:0.508 Test-Acc:0.758\n",
      " I:150 Train-Err:0.145 Train-Acc:0.991 Test-Err:0.513 Test-Acc:0.7558\n",
      " I:160 Train-Err:0.141 Train-Acc:0.992 Test-Err:0.518 Test-Acc:0.7553\n",
      " I:170 Train-Err:0.138 Train-Acc:0.992 Test-Err:0.524 Test-Acc:0.751\n",
      " I:180 Train-Err:0.135 Train-Acc:0.995 Test-Err:0.528 Test-Acc:0.7505\n",
      " I:190 Train-Err:0.132 Train-Acc:0.995 Test-Err:0.533 Test-Acc:0.7482\n",
      " I:200 Train-Err:0.130 Train-Acc:0.998 Test-Err:0.538 Test-Acc:0.7464\n",
      " I:210 Train-Err:0.127 Train-Acc:0.998 Test-Err:0.544 Test-Acc:0.7446\n",
      " I:220 Train-Err:0.125 Train-Acc:0.998 Test-Err:0.552 Test-Acc:0.7416\n",
      " I:230 Train-Err:0.123 Train-Acc:0.998 Test-Err:0.560 Test-Acc:0.7372\n",
      " I:240 Train-Err:0.121 Train-Acc:0.998 Test-Err:0.569 Test-Acc:0.7344\n",
      " I:250 Train-Err:0.120 Train-Acc:0.999 Test-Err:0.577 Test-Acc:0.7316\n",
      " I:260 Train-Err:0.118 Train-Acc:0.999 Test-Err:0.585 Test-Acc:0.729\n",
      " I:270 Train-Err:0.117 Train-Acc:0.999 Test-Err:0.593 Test-Acc:0.7259\n",
      " I:280 Train-Err:0.115 Train-Acc:0.999 Test-Err:0.600 Test-Acc:0.723\n",
      " I:290 Train-Err:0.114 Train-Acc:0.999 Test-Err:0.607 Test-Acc:0.7196\n",
      " I:300 Train-Err:0.113 Train-Acc:0.999 Test-Err:0.614 Test-Acc:0.7183\n",
      " I:310 Train-Err:0.112 Train-Acc:0.999 Test-Err:0.622 Test-Acc:0.7165\n",
      " I:320 Train-Err:0.111 Train-Acc:0.999 Test-Err:0.629 Test-Acc:0.7133\n",
      " I:330 Train-Err:0.110 Train-Acc:0.999 Test-Err:0.637 Test-Acc:0.7125\n",
      " I:340 Train-Err:0.109 Train-Acc:1.099 Test-Err:0.645 Test-Acc:0.71\n",
      " I:349 Train-Err:0.108 Train-Acc:1.0 Test-Err:0.653 Test-Acc:0.7073\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "np.random.seed(1)\n",
    "\n",
    "relu = lambda x:(x>=0) * x # returns x if x > 0, return 0 otherwise\n",
    "relu2deriv = lambda x: x>=0 # returns 1 for input > 0, return 0 otherwise\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                        np.argmax(labels[i:i+1]))\n",
    "\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\\n",
    "                                    * relu2deriv(layer_1)\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    sys.stdout.write(\"\\r I:\"+str(j)+ \\\n",
    "                     \" Train-Err:\" + str(error/float(len(images)))[0:5] +\\\n",
    "                     \" Train-Acc:\" + str(correct_cnt/float(len(images))))\n",
    "    \n",
    "    if(j % 10 == 0 or j == iterations-1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                            np.argmax(test_labels[i:i+1]))\n",
    "        sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
